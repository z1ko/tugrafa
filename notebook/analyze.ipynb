{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "\n",
    "This script is used to load data from the Cassandra cluster, generate the RDDs and run queries on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione del progetto\n",
    "\n",
    "TUGRAFA_SPARK_HOST      = \"spark://localhost:7077\" \n",
    "TUGRAFA_SPARK_APP_NAME  = \"Tugrafa\"\n",
    "TUGRAFA_DATA_FOLDER     = \"notebook/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Spark cluster master node at spark://localhost:7077\n",
      "22/10/26 23:39:28 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://portatile.homenet.telecomitalia.it:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://localhost:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tugrafa</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f88e3a14040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connetti al cluster manager di Spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(f\"Connecting to Spark cluster master node at {TUGRAFA_SPARK_HOST}\")\n",
    "spark = SparkSession.builder.master(TUGRAFA_SPARK_HOST).appName(TUGRAFA_SPARK_APP_NAME).getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Disabilita per performance\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all csv files...\n",
      "root\n",
      " |-- 30-12-14: string (nullable = true)\n",
      " |-- 18:40:38: string (nullable = true)\n",
      " |-- Tomba Giulietta: string (nullable = true)\n",
      " |-- 40: long (nullable = true)\n",
      " |-- 049B31523F3880: string (nullable = true)\n",
      " |-- 30-12-14.1: string (nullable = true)\n",
      " |-- in: string (nullable = true)\n",
      " |-- 1: long (nullable = true)\n",
      " |-- 24 Ore: string (nullable = true)\n",
      "\n",
      "22/10/26 23:49:06 ERROR TaskSchedulerImpl: Lost executor 2 on 172.23.0.5: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/10/26 23:49:06 WARN StandaloneAppClient$ClientEndpoint: Connection to 40a8306ccc3a:7077 failed; waiting for master to reconnect...\n",
      "22/10/26 23:49:06 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection...\n",
      "22/10/26 23:49:06 ERROR TaskSchedulerImpl: Lost executor 0 on 172.23.0.3: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/10/26 23:49:06 ERROR TaskSchedulerImpl: Lost executor 1 on 172.23.0.2: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n"
     ]
    }
   ],
   "source": [
    "# Carica dati dai CSV (TODO: Usare Cassandra o un altro database NoSQL)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Loading all csv files...\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/dati_2014.csv\")\n",
    "swipes = spark.createDataFrame(df)\n",
    "swipes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closes connection\n",
    "spark.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
